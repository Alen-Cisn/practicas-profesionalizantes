#!/usr/bin/env python3
"""
Ejemplo de Procesamiento por Lotes
Demuestra cÃ³mo procesar mÃºltiples consultas y anÃ¡lisis automatizados
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from historical_term_analyzer import HistoricalTermAnalyzer
import json
import time
from datetime import datetime


def batch_analysis_by_years():
    """
    AnÃ¡lisis por lotes dividido por aÃ±os individuales
    """
    
    print("="*60)
    print("PROCESAMIENTO POR LOTES - ANÃLISIS POR AÃ‘OS")
    print("="*60)
    print()
    
    analyzer = HistoricalTermAnalyzer(rate_limit_delay=4.0)
    
    # Definir aÃ±os a analizar
    target_years = [1996, 1998, 2000, 2002, 2004]
    
    batch_results = {}
    total_start_time = time.time()
    
    print(f"ğŸ“… Analizando {len(target_years)} aÃ±os individuales:")
    print(f"AÃ±os objetivo: {target_years}")
    print()
    
    for i, year in enumerate(target_years, 1):
        print(f"ğŸ” Procesando aÃ±o {year} ({i}/{len(target_years)})...")
        year_start_time = time.time()
        
        try:
            # AnÃ¡lisis de un solo aÃ±o
            results = analyzer.analyze_period(
                start_year=year,
                end_year=year,
                max_documents=25,  # Documentos por aÃ±o
                language='eng'
            )
            
            if 'error' not in results:
                year_duration = time.time() - year_start_time
                
                batch_results[str(year)] = {
                    'year': year,
                    'processing_time_minutes': year_duration / 60,
                    'documents_found': results['summary']['total_documents'],
                    'documents_with_content': results['summary']['documents_with_content'],
                    'unique_terms': results['summary']['total_unique_terms'],
                    'top_10_terms': results['top_terms'][:10]
                }
                
                print(f"  âœ… Completado en {year_duration/60:.1f} min")
                print(f"  ğŸ“„ {results['summary']['total_documents']} documentos procesados")
                print(f"  ğŸ”¤ {results['summary']['total_unique_terms']} tÃ©rminos Ãºnicos")
                
            else:
                print(f"  âŒ Error en aÃ±o {year}: {results['error']}")
                batch_results[str(year)] = {'error': results['error']}
                
        except Exception as e:
            print(f"  âŒ ExcepciÃ³n en aÃ±o {year}: {e}")
            batch_results[str(year)] = {'exception': str(e)}
        
        print()
    
    total_duration = time.time() - total_start_time
    
    # Generar resumen del lote
    print("ğŸ“Š RESUMEN DEL PROCESAMIENTO POR LOTES:")
    print("=" * 50)
    print(f"Tiempo total: {total_duration/60:.1f} minutos")
    print(f"AÃ±os procesados exitosamente: {len([r for r in batch_results.values() if 'error' not in r and 'exception' not in r])}")
    print()
    
    # Mostrar estadÃ­sticas por aÃ±o
    for year, data in batch_results.items():
        if 'error' not in data and 'exception' not in data:
            print(f"ğŸ“… {year}:")
            print(f"  Documentos: {data['documents_with_content']}")
            print(f"  TÃ©rminos Ãºnicos: {data['unique_terms']}")
            if data['top_10_terms']:
                top_3 = data['top_10_terms'][:3]
                print(f"  Top 3: {', '.join([f'{term}({freq})' for term, freq in top_3])}")
            print()
    
    # Exportar resultados del lote
    batch_metadata = {
        'batch_info': {
            'processing_date': datetime.now().isoformat(),
            'total_processing_time_minutes': total_duration / 60,
            'years_processed': target_years,
            'successful_years': len([r for r in batch_results.values() if 'error' not in r]),
            'documents_per_year': 25
        },
        'results': batch_results
    }
    
    with open('batch_analysis_by_years.json', 'w', encoding='utf-8') as f:
        json.dump(batch_metadata, f, indent=2, ensure_ascii=False)
    
    print("ğŸ“ Resultados del lote exportados a: batch_analysis_by_years.json")
    
    return batch_results


def batch_thematic_analysis():
    """
    AnÃ¡lisis por lotes de diferentes temÃ¡ticas
    """
    
    print("\n" + "="*60)
    print("PROCESAMIENTO TEMÃTICO POR LOTES")
    print("="*60)
    print()
    
    analyzer = HistoricalTermAnalyzer(rate_limit_delay=4.5)
    
    # Definir temÃ¡ticas con sus tÃ©rminos especÃ­ficos
    themes = {
        'Technology': ['computer', 'software', 'digital', 'technology', 'programming'],
        'Internet': ['internet', 'website', 'web', 'online', 'email', 'browser'],
        'Business': ['business', 'company', 'market', 'economy', 'commerce', 'financial'],
        'Communication': ['communication', 'media', 'news', 'information', 'network']
    }
    
    thematic_results = {}
    
    print(f"ğŸ¯ Analizando {len(themes)} temÃ¡ticas diferentes:")
    for theme in themes.keys():
        print(f"  â€¢ {theme}")
    print()
    
    for theme, keywords in themes.items():
        print(f"ğŸ” Procesando temÃ¡tica: {theme}")
        print(f"  Palabras clave: {', '.join(keywords[:3])}...")
        
        try:
            results = analyzer.analyze_period(
                start_year=1997,
                end_year=2003,
                max_documents=40,
                language='eng',
                search_terms=keywords
            )
            
            if 'error' not in results:
                # Filtrar tÃ©rminos relacionados con la temÃ¡tica
                theme_terms = {}
                for term, freq in results['frequencies'].items():
                    if (term in keywords or 
                        any(keyword.lower() in term.lower() for keyword in keywords)):
                        theme_terms[term] = freq
                
                theme_top = sorted(theme_terms.items(), key=lambda x: x[1], reverse=True)[:10]
                
                thematic_results[theme] = {
                    'keywords_searched': keywords,
                    'total_documents': results['summary']['total_documents'],
                    'documents_with_content': results['summary']['documents_with_content'],
                    'theme_specific_terms': len(theme_terms),
                    'top_theme_terms': theme_top,
                    'processing_time': results['summary']['elapsed_time_minutes']
                }
                
                print(f"  âœ… {results['summary']['total_documents']} docs, {len(theme_terms)} tÃ©rminos temÃ¡ticos")
                
            else:
                print(f"  âŒ Error: {results['error']}")
                thematic_results[theme] = {'error': results['error']}
                
        except Exception as e:
            print(f"  âŒ ExcepciÃ³n: {e}")
            thematic_results[theme] = {'exception': str(e)}
        
        print()
    
    # Mostrar comparativa temÃ¡tica
    print("ğŸ“ˆ COMPARATIVA TEMÃTICA:")
    print("=" * 40)
    
    for theme, data in thematic_results.items():
        if 'error' not in data and 'exception' not in data:
            print(f"\nğŸ¯ {theme}:")
            print(f"  Documentos procesados: {data['documents_with_content']}")
            print(f"  TÃ©rminos temÃ¡ticos encontrados: {data['theme_specific_terms']}")
            if data['top_theme_terms']:
                print(f"  TÃ©rmino principal: {data['top_theme_terms'][0][0]} ({data['top_theme_terms'][0][1]} veces)")
    
    # Exportar anÃ¡lisis temÃ¡tico
    thematic_metadata = {
        'thematic_batch_info': {
            'processing_date': datetime.now().isoformat(),
            'period_analyzed': '1997-2003',
            'themes_count': len(themes),
            'documents_per_theme': 40
        },
        'themes': thematic_results
    }
    
    with open('batch_thematic_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(thematic_metadata, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“ AnÃ¡lisis temÃ¡tico exportado a: batch_thematic_analysis.json")
    
    return thematic_results


def automated_quality_report(batch_results, thematic_results):
    """
    Generar reporte automatizado de calidad del procesamiento por lotes
    """
    
    print("\n" + "="*60)
    print("REPORTE AUTOMATIZADO DE CALIDAD")
    print("="*60)
    print()
    
    # AnÃ¡lisis de calidad por aÃ±os
    years_analysis = {
        'successful_years': 0,
        'failed_years': 0,
        'total_documents': 0,
        'avg_unique_terms': 0,
        'processing_efficiency': []
    }
    
    successful_year_data = []
    for year, data in batch_results.items():
        if 'error' not in data and 'exception' not in data:
            years_analysis['successful_years'] += 1
            years_analysis['total_documents'] += data['documents_with_content']
            successful_year_data.append(data)
        else:
            years_analysis['failed_years'] += 1
    
    if successful_year_data:
        years_analysis['avg_unique_terms'] = sum(d['unique_terms'] for d in successful_year_data) / len(successful_year_data)
        years_analysis['avg_processing_time'] = sum(d['processing_time_minutes'] for d in successful_year_data) / len(successful_year_data)
    
    # AnÃ¡lisis de calidad temÃ¡tico
    themes_analysis = {
        'successful_themes': 0,
        'failed_themes': 0,
        'total_thematic_documents': 0,
        'themes_efficiency': {}
    }
    
    for theme, data in thematic_results.items():
        if 'error' not in data and 'exception' not in data:
            themes_analysis['successful_themes'] += 1
            themes_analysis['total_thematic_documents'] += data['documents_with_content']
            themes_analysis['themes_efficiency'][theme] = {
                'docs_per_minute': data['documents_with_content'] / max(data['processing_time'], 0.1),
                'terms_found': data['theme_specific_terms']
            }
        else:
            themes_analysis['failed_themes'] += 1
    
    # Generar reporte
    quality_report = {
        'report_metadata': {
            'generated_at': datetime.now().isoformat(),
            'report_type': 'batch_processing_quality'
        },
        'yearly_analysis': years_analysis,
        'thematic_analysis': themes_analysis,
        'overall_metrics': {
            'total_processing_success_rate': (
                (years_analysis['successful_years'] + themes_analysis['successful_themes']) /
                max((years_analysis['successful_years'] + years_analysis['failed_years'] + 
                     themes_analysis['successful_themes'] + themes_analysis['failed_themes']), 1)
            ) * 100,
            'total_documents_processed': years_analysis['total_documents'] + themes_analysis['total_thematic_documents']
        },
        'recommendations': []
    }
    
    # Generar recomendaciones
    if years_analysis['failed_years'] > 0:
        quality_report['recommendations'].append(
            f"Se encontraron {years_analysis['failed_years']} aÃ±os con errores. "
            "Considere verificar la conectividad y aumentar el rate_limit_delay."
        )
    
    if themes_analysis['failed_themes'] > 0:
        quality_report['recommendations'].append(
            f"Se encontraron {themes_analysis['failed_themes']} temÃ¡ticas con errores. "
            "Considere usar tÃ©rminos de bÃºsqueda mÃ¡s especÃ­ficos."
        )
    
    if quality_report['overall_metrics']['total_processing_success_rate'] > 90:
        quality_report['recommendations'].append("Excelente tasa de Ã©xito en el procesamiento por lotes.")
    elif quality_report['overall_metrics']['total_processing_success_rate'] > 70:
        quality_report['recommendations'].append("Buena tasa de Ã©xito, pero hay margen de mejora.")
    else:
        quality_report['recommendations'].append("Baja tasa de Ã©xito. Revise configuraciÃ³n y conectividad.")
    
    # Mostrar reporte
    print("ğŸ“‹ MÃ‰TRICAS DE CALIDAD:")
    print(f"âœ… AÃ±os procesados exitosamente: {years_analysis['successful_years']}")
    print(f"âŒ AÃ±os con errores: {years_analysis['failed_years']}")
    print(f"âœ… TemÃ¡ticas procesadas exitosamente: {themes_analysis['successful_themes']}")
    print(f"âŒ TemÃ¡ticas con errores: {themes_analysis['failed_themes']}")
    print(f"ğŸ“Š Tasa de Ã©xito general: {quality_report['overall_metrics']['total_processing_success_rate']:.1f}%")
    print(f"ğŸ“„ Total de documentos procesados: {quality_report['overall_metrics']['total_documents_processed']}")
    
    if years_analysis['avg_unique_terms']:
        print(f"ğŸ”¤ Promedio de tÃ©rminos Ãºnicos por aÃ±o: {years_analysis['avg_unique_terms']:.0f}")
    
    print("\nğŸ’¡ RECOMENDACIONES:")
    for i, rec in enumerate(quality_report['recommendations'], 1):
        print(f"{i}. {rec}")
    
    # Exportar reporte
    with open('batch_quality_report.json', 'w', encoding='utf-8') as f:
        json.dump(quality_report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“ Reporte de calidad exportado a: batch_quality_report.json")
    
    return quality_report


def main():
    """FunciÃ³n principal para procesamiento por lotes"""
    
    print("ğŸ”„ PROCESAMIENTO POR LOTES - ANALIZADOR HISTÃ“RICO")
    print("Este script ejecuta mÃºltiples anÃ¡lisis automÃ¡ticamente")
    print()
    
    try:
        # Ejecutar anÃ¡lisis por aÃ±os
        batch_results = batch_analysis_by_years()
        
        # Ejecutar anÃ¡lisis temÃ¡tico
        thematic_results = batch_thematic_analysis()
        
        # Generar reporte de calidad
        quality_report = automated_quality_report(batch_results, thematic_results)
        
        print("\n" + "="*60)
        print("âœ… PROCESAMIENTO POR LOTES COMPLETADO")
        print("Se han generado los siguientes archivos:")
        print("  â€¢ batch_analysis_by_years.json - AnÃ¡lisis por aÃ±os")
        print("  â€¢ batch_thematic_analysis.json - AnÃ¡lisis temÃ¡tico")
        print("  â€¢ batch_quality_report.json - Reporte de calidad")
        print("="*60)
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ Procesamiento por lotes interrumpido por el usuario")
    except Exception as e:
        print(f"\nâŒ Error inesperado en procesamiento por lotes: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()