#!/usr/bin/env python3
"""
Ejemplo de Procesamiento por Lotes
Demuestra c√≥mo procesar m√∫ltiples consultas y an√°lisis automatizados
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from historical_term_analyzer import HistoricalTermAnalyzer
import json
import time
from datetime import datetime


def batch_analysis_by_years():
    """
    An√°lisis por lotes dividido por a√±os individuales
    """
    
    print("="*60)
    print("PROCESAMIENTO POR LOTES - AN√ÅLISIS POR A√ëOS")
    print("="*60)
    print()
    
    analyzer = HistoricalTermAnalyzer(rate_limit_delay=4.0)
    
    # Definir a√±os a analizar
    target_years = [1996, 1998, 2000, 2002, 2004]
    
    batch_results = {}
    total_start_time = time.time()
    
    print(f"üìÖ Analizando {len(target_years)} a√±os individuales:")
    print(f"A√±os objetivo: {target_years}")
    print()
    
    for i, year in enumerate(target_years, 1):
        print(f"üîç Procesando a√±o {year} ({i}/{len(target_years)})...")
        year_start_time = time.time()
        
        try:
            # An√°lisis de un solo a√±o
            results = analyzer.analyze_period(
                start_year=year,
                end_year=year,
                max_documents=25,  # Documentos por a√±o
                language='eng'
            )
            
            if 'error' not in results:
                year_duration = time.time() - year_start_time
                
                batch_results[str(year)] = {
                    'year': year,
                    'processing_time_minutes': year_duration / 60,
                    'documents_found': results['summary']['total_documents'],
                    'documents_with_content': results['summary']['documents_with_content'],
                    'unique_terms': results['summary']['total_unique_terms'],
                    'top_10_terms': results['top_terms'][:10]
                }
                
                print(f"  ‚úÖ Completado en {year_duration/60:.1f} min")
                print(f"  üìÑ {results['summary']['total_documents']} documentos procesados")
                print(f"  üî§ {results['summary']['total_unique_terms']} t√©rminos √∫nicos")
                
            else:
                print(f"  ‚ùå Error en a√±o {year}: {results['error']}")
                batch_results[str(year)] = {'error': results['error']}
                
        except Exception as e:
            print(f"  ‚ùå Excepci√≥n en a√±o {year}: {e}")
            batch_results[str(year)] = {'exception': str(e)}
        
        print()
    
    total_duration = time.time() - total_start_time
    
    # Generar resumen del lote
    print("üìä RESUMEN DEL PROCESAMIENTO POR LOTES:")
    print("=" * 50)
    print(f"Tiempo total: {total_duration/60:.1f} minutos")
    print(f"A√±os procesados exitosamente: {len([r for r in batch_results.values() if 'error' not in r and 'exception' not in r])}")
    print()
    
    # Mostrar estad√≠sticas por a√±o
    for year, data in batch_results.items():
        if 'error' not in data and 'exception' not in data:
            print(f"üìÖ {year}:")
            print(f"  Documentos: {data['documents_with_content']}")
            print(f"  T√©rminos √∫nicos: {data['unique_terms']}")
            if data['top_10_terms']:
                top_3 = data['top_10_terms'][:3]
                print(f"  Top 3: {', '.join([f'{term}({freq})' for term, freq in top_3])}")
            print()
    
    # Exportar resultados del lote
    batch_metadata = {
        'batch_info': {
            'processing_date': datetime.now().isoformat(),
            'total_processing_time_minutes': total_duration / 60,
            'years_processed': target_years,
            'successful_years': len([r for r in batch_results.values() if 'error' not in r]),
            'documents_per_year': 25
        },
        'results': batch_results
    }
    
    with open('batch_analysis_by_years.json', 'w', encoding='utf-8') as f:
        json.dump(batch_metadata, f, indent=2, ensure_ascii=False)
    
    print("üìÅ Resultados del lote exportados a: batch_analysis_by_years.json")
    
    return batch_results


def batch_thematic_analysis():
    """
    An√°lisis por lotes de diferentes tem√°ticas
    """
    
    print("\n" + "="*60)
    print("PROCESAMIENTO TEM√ÅTICO POR LOTES")
    print("="*60)
    print()
    
    analyzer = HistoricalTermAnalyzer(rate_limit_delay=4.5)
    
    # Definir tem√°ticas con sus t√©rminos espec√≠ficos
    themes = {
        'Technology': ['computer', 'software', 'digital', 'technology', 'programming'],
        'Internet': ['internet', 'website', 'web', 'online', 'email', 'browser'],
        'Business': ['business', 'company', 'market', 'economy', 'commerce', 'financial'],
        'Communication': ['communication', 'media', 'news', 'information', 'network']
    }
    
    thematic_results = {}
    
    print(f"üéØ Analizando {len(themes)} tem√°ticas diferentes:")
    for theme in themes.keys():
        print(f"  ‚Ä¢ {theme}")
    print()
    
    for theme, keywords in themes.items():
        print(f"üîç Procesando tem√°tica: {theme}")
        print(f"  Palabras clave: {', '.join(keywords[:3])}...")
        
        try:
            results = analyzer.analyze_period(
                start_year=1997,
                end_year=2003,
                max_documents=40,
                language='eng',
                search_terms=keywords
            )
            
            if 'error' not in results:
                # Filtrar t√©rminos relacionados con la tem√°tica
                theme_terms = {}
                for term, freq in results['frequencies'].items():
                    if (term in keywords or 
                        any(keyword.lower() in term.lower() for keyword in keywords)):
                        theme_terms[term] = freq
                
                theme_top = sorted(theme_terms.items(), key=lambda x: x[1], reverse=True)[:10]
                
                thematic_results[theme] = {
                    'keywords_searched': keywords,
                    'total_documents': results['summary']['total_documents'],
                    'documents_with_content': results['summary']['documents_with_content'],
                    'theme_specific_terms': len(theme_terms),
                    'top_theme_terms': theme_top,
                    'processing_time': results['summary']['elapsed_time_minutes']
                }
                
                print(f"  ‚úÖ {results['summary']['total_documents']} docs, {len(theme_terms)} t√©rminos tem√°ticos")
                
            else:
                print(f"  ‚ùå Error: {results['error']}")
                thematic_results[theme] = {'error': results['error']}
                
        except Exception as e:
            print(f"  ‚ùå Excepci√≥n: {e}")
            thematic_results[theme] = {'exception': str(e)}
        
        print()
    
    # Mostrar comparativa tem√°tica
    print("üìà COMPARATIVA TEM√ÅTICA:")
    print("=" * 40)
    
    for theme, data in thematic_results.items():
        if 'error' not in data and 'exception' not in data:
            print(f"\nüéØ {theme}:")
            print(f"  Documentos procesados: {data['documents_with_content']}")
            print(f"  T√©rminos tem√°ticos encontrados: {data['theme_specific_terms']}")
            if data['top_theme_terms']:
                print(f"  T√©rmino principal: {data['top_theme_terms'][0][0]} ({data['top_theme_terms'][0][1]} veces)")
    
    # Exportar an√°lisis tem√°tico
    thematic_metadata = {
        'thematic_batch_info': {
            'processing_date': datetime.now().isoformat(),
            'period_analyzed': '1997-2003',
            'themes_count': len(themes),
            'documents_per_theme': 40
        },
        'themes': thematic_results
    }
    
    with open('batch_thematic_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(thematic_metadata, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìÅ An√°lisis tem√°tico exportado a: batch_thematic_analysis.json")
    
    return thematic_results


def automated_quality_report(batch_results, thematic_results):
    """
    Generar reporte automatizado de calidad del procesamiento por lotes
    """
    
    print("\n" + "="*60)
    print("REPORTE AUTOMATIZADO DE CALIDAD")
    print("="*60)
    print()
    
    # An√°lisis de calidad por a√±os
    years_analysis = {
        'successful_years': 0,
        'failed_years': 0,
        'total_documents': 0,
        'avg_unique_terms': 0,
        'processing_efficiency': []
    }
    
    successful_year_data = []
    for year, data in batch_results.items():
        if 'error' not in data and 'exception' not in data:
            years_analysis['successful_years'] += 1
            years_analysis['total_documents'] += data['documents_with_content']
            successful_year_data.append(data)
        else:
            years_analysis['failed_years'] += 1
    
    if successful_year_data:
        years_analysis['avg_unique_terms'] = sum(d['unique_terms'] for d in successful_year_data) / len(successful_year_data)
        years_analysis['avg_processing_time'] = sum(d['processing_time_minutes'] for d in successful_year_data) / len(successful_year_data)
    
    # An√°lisis de calidad tem√°tico
    themes_analysis = {
        'successful_themes': 0,
        'failed_themes': 0,
        'total_thematic_documents': 0,
        'themes_efficiency': {}
    }
    
    for theme, data in thematic_results.items():
        if 'error' not in data and 'exception' not in data:
            themes_analysis['successful_themes'] += 1
            themes_analysis['total_thematic_documents'] += data['documents_with_content']
            themes_analysis['themes_efficiency'][theme] = {
                'docs_per_minute': data['documents_with_content'] / max(data['processing_time'], 0.1),
                'terms_found': data['theme_specific_terms']
            }
        else:
            themes_analysis['failed_themes'] += 1
    
    # Generar reporte
    quality_report = {
        'report_metadata': {
            'generated_at': datetime.now().isoformat(),
            'report_type': 'batch_processing_quality'
        },
        'yearly_analysis': years_analysis,
        'thematic_analysis': themes_analysis,
        'overall_metrics': {
            'total_processing_success_rate': (
                (years_analysis['successful_years'] + themes_analysis['successful_themes']) /
                max((years_analysis['successful_years'] + years_analysis['failed_years'] + 
                     themes_analysis['successful_themes'] + themes_analysis['failed_themes']), 1)
            ) * 100,
            'total_documents_processed': years_analysis['total_documents'] + themes_analysis['total_thematic_documents']
        },
        'recommendations': []
    }
    
    # Generar recomendaciones
    if years_analysis['failed_years'] > 0:
        quality_report['recommendations'].append(
            f"Se encontraron {years_analysis['failed_years']} a√±os con errores. "
            "Considere verificar la conectividad y aumentar el rate_limit_delay."
        )
    
    if themes_analysis['failed_themes'] > 0:
        quality_report['recommendations'].append(
            f"Se encontraron {themes_analysis['failed_themes']} tem√°ticas con errores. "
            "Considere usar t√©rminos de b√∫squeda m√°s espec√≠ficos."
        )
    
    if quality_report['overall_metrics']['total_processing_success_rate'] > 90:
        quality_report['recommendations'].append("Excelente tasa de √©xito en el procesamiento por lotes.")
    elif quality_report['overall_metrics']['total_processing_success_rate'] > 70:
        quality_report['recommendations'].append("Buena tasa de √©xito, pero hay margen de mejora.")
    else:
        quality_report['recommendations'].append("Baja tasa de √©xito. Revise configuraci√≥n y conectividad.")
    
    # Mostrar reporte
    print("üìã M√âTRICAS DE CALIDAD:")
    print(f"‚úÖ A√±os procesados exitosamente: {years_analysis['successful_years']}")
    print(f"‚ùå A√±os con errores: {years_analysis['failed_years']}")
    print(f"‚úÖ Tem√°ticas procesadas exitosamente: {themes_analysis['successful_themes']}")
    print(f"‚ùå Tem√°ticas con errores: {themes_analysis['failed_themes']}")
    print(f"üìä Tasa de √©xito general: {quality_report['overall_metrics']['total_processing_success_rate']:.1f}%")
    print(f"üìÑ Total de documentos procesados: {quality_report['overall_metrics']['total_documents_processed']}")
    
    if years_analysis['avg_unique_terms']:
        print(f"üî§ Promedio de t√©rminos √∫nicos por a√±o: {years_analysis['avg_unique_terms']:.0f}")
    
    print("\nüí° RECOMENDACIONES:")
    for i, rec in enumerate(quality_report['recommendations'], 1):
        print(f"{i}. {rec}")
    
    # Exportar reporte
    with open('batch_quality_report.json', 'w', encoding='utf-8') as f:
        json.dump(quality_report, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìÅ Reporte de calidad exportado a: batch_quality_report.json")
    
    return quality_report


def main():
    """Funci√≥n principal para procesamiento por lotes"""
    
    print("üîÑ PROCESAMIENTO POR LOTES - ANALIZADOR HIST√ìRICO")
    print("Este script ejecuta m√∫ltiples an√°lisis autom√°ticamente")
    print()
    
    try:
        # Ejecutar an√°lisis por a√±os
        batch_results = batch_analysis_by_years()
        
        # Ejecutar an√°lisis tem√°tico
        thematic_results = batch_thematic_analysis()
        
        # Generar reporte de calidad
        quality_report = automated_quality_report(batch_results, thematic_results)
        
        print("\n" + "="*60)
        print("‚úÖ PROCESAMIENTO POR LOTES COMPLETADO")
        print("Se han generado los siguientes archivos:")
        print("  ‚Ä¢ batch_analysis_by_years.json - An√°lisis por a√±os")
        print("  ‚Ä¢ batch_thematic_analysis.json - An√°lisis tem√°tico")
        print("  ‚Ä¢ batch_quality_report.json - Reporte de calidad")
        print("="*60)
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Procesamiento por lotes interrumpido por el usuario")
    except Exception as e:
        print(f"\n‚ùå Error inesperado en procesamiento por lotes: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()