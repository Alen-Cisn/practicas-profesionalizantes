# Analizador Hist√≥rico de T√©rminos

## Descripci√≥n del Proyecto

El **Analizador Hist√≥rico de T√©rminos** es un sistema desarrollado para investigadores socioling√º√≠sticos que permite analizar las palabras m√°s utilizadas en documentos web hist√≥ricos durante per√≠odos espec√≠ficos. El sistema utiliza la API de Internet Archive para acceder a p√°ginas web archivadas y realizar an√°lisis de frecuencia de t√©rminos.

## Caracter√≠sticas Principales

### üîç Funcionalidades Implementadas - Primera Iteraci√≥n

- **B√∫squeda temporal**: Define per√≠odo hist√≥rico espec√≠fico (fecha desde/hasta)
- **Filtrado por idioma**: Procesa √∫nicamente documentos en ingl√©s
- **Control de volumen**: Limita n√∫mero de documentos analizados (configurable, m√≠nimo 600)
- **Procesamiento web**: Extrae y procesa contenido de p√°ginas web hist√≥ricas
- **An√°lisis de frecuencias**: Cuenta ocurrencias de t√©rminos sin lematizaci√≥n
- **Filtrado de ruido**: Elimina stop words manteniendo t√©rminos relevantes

### üèóÔ∏è Arquitectura del Sistema

```
HistoricalTermAnalyzer (Orquestador principal)
‚îú‚îÄ‚îÄ InternetArchiveClient (Acceso a API)
‚îú‚îÄ‚îÄ TextProcessor (Procesamiento NLP)
‚îú‚îÄ‚îÄ Document (Modelo de datos)
‚îú‚îÄ‚îÄ SessionMemory (Memoria temporal)
‚îú‚îÄ‚îÄ Exporter (Exportaci√≥n resultados)
‚îî‚îÄ‚îÄ Visualizer (Gr√°ficos)
```

## Instalaci√≥n y Configuraci√≥n

### Requisitos del Sistema

- Python 3.8 o superior
- Conexi√≥n a Internet estable
- Bibliotecas requeridas:

```bash
pip install requests
```

### Bibliotecas Est√°ndar Utilizadas

El proyecto utiliza principalmente bibliotecas est√°ndar de Python:
- `requests` - Para peticiones HTTP
- `time` - Para rate limiting
- `re` - Para procesamiento de texto
- `json` - Para manejo de datos JSON
- `datetime` - Para manejo de fechas
- `typing` - Para type hints
- `logging` - Para logging del sistema
- `collections` - Para Counter y estructuras de datos
- `csv` - Para exportaci√≥n a CSV
- `unittest` - Para testing

## Uso del Sistema

### Uso B√°sico

```python
from historical_term_analyzer import HistoricalTermAnalyzer

# Inicializar analizador
analyzer = HistoricalTermAnalyzer(rate_limit_delay=4.0)

# An√°lizar per√≠odo hist√≥rico
results = analyzer.analyze_period(
    start_year=1995,
    end_year=2005,
    max_documents=600,
    language='eng'
)

# Mostrar resultados
analyzer.display_results(results, top_n=25)

# Exportar resultados
analyzer.export_results(results)
```

### Configuraci√≥n Avanzada

```python
# Con t√©rminos de b√∫squeda espec√≠ficos
results = analyzer.analyze_period(
    start_year=1998,
    end_year=2002,
    max_documents=800,
    language='eng',
    search_terms=['internet', 'computer', 'technology']
)

# Con rate limiting personalizado (recomendado: 4-6 segundos)
analyzer = HistoricalTermAnalyzer(rate_limit_delay=5.0)
```

## Especificaciones T√©cnicas

### Clase InternetArchiveClient

Interfaz robusta para interactuar con Internet Archive:

#### Funciones Principales

- `search_items()`: Busca documentos web hist√≥ricos con filtros
- `download_text()`: Descarga contenido textual de documentos espec√≠ficos
- `validate_english_content()`: Valida que el contenido est√© en ingl√©s

#### Filtros Implementados

- **Temporal**: `date:[1995-01-01 TO 2005-12-31]`
- **Tipo de contenido**: `mediatype:web`
- **Idioma**: `language:eng` o validaci√≥n post-descarga
- **Colecci√≥n**: `collection:web` (Wayback Machine)

#### Rate Limiting

- L√≠mite respetado: 6-15 requests por minuto
- Delay configurable entre requests (por defecto: 4 segundos)
- Reintentos autom√°ticos en caso de errores temporales

### Clase TextProcessor

Procesador de texto para an√°lisis de frecuencias:

- Extracci√≥n de t√©rminos relevantes (3+ caracteres)
- Filtrado de 200+ stop words en ingl√©s
- C√°lculo de frecuencias sin lematizaci√≥n
- Obtenci√≥n de t√©rminos m√°s frecuentes

### Validaciones y Controles de Calidad

#### Validaci√≥n de Idioma Ingl√©s

El sistema implementa un algoritmo de detecci√≥n de idioma que:

- Analiza patrones de palabras comunes en ingl√©s
- Verifica ratio de caracteres no latinos
- Requiere m√≠nimo 15% de palabras en ingl√©s reconocidas
- M√°ximo 5% de caracteres no latinos

#### Filtros de Calidad

- Contenido m√≠nimo: 100 caracteres
- Palabras m√≠nimas: 10 palabras v√°lidas
- Identificadores v√°lidos: m√≠nimo 5 caracteres
- Validaci√≥n temporal: documentos dentro del rango especificado

## Limitaciones y Consideraciones

### Limitaciones T√©cnicas

- **Rate Limiting**: M√°ximo 15 requests por minuto
- **Tiempo de procesamiento**: ~90 minutos para 600 documentos
- **Idioma**: Solo procesamiento de contenido en ingl√©s
- **Tipo de contenido**: Solo p√°ginas web archivadas (mediatype:web)

### Consideraciones de Uso

- El sistema respeta las pol√≠ticas de uso de Internet Archive
- Se recomienda usar durante horas de menor tr√°fico
- Los resultados pueden variar seg√∫n disponibilidad de contenido archivado
- La calidad del an√°lisis depende de la calidad del contenido original

## Resultados y Exportaci√≥n

### Formatos de Salida

#### CSV (t√©rminos principales)
```csv
T√©rmino,Frecuencia
computer,1250
internet,890
technology,756
```

#### JSON (datos completos)
```json
{
  "summary": {
    "total_documents": 600,
    "documents_with_content": 580,
    "total_unique_terms": 15420,
    "elapsed_time_minutes": 85.2
  },
  "top_terms": [...],
  "frequencies": {...},
  "analysis_metadata": {...}
}
```

### M√©tricas de Calidad

El sistema proporciona m√©tricas detalladas:

- **Tasa de √©xito de descargas**: % de documentos procesados exitosamente
- **Distribuci√≥n temporal**: Documentos por a√±o
- **Validaci√≥n de idioma**: % de documentos validados como ingl√©s
- **Tiempo de procesamiento**: Duraci√≥n total del an√°lisis

## Casos de Uso

### Investigaci√≥n Socioling√º√≠stica

- An√°lisis de evoluci√≥n terminol√≥gica en per√≠odos espec√≠ficos
- Estudio de emergencia de nuevos t√©rminos tecnol√≥gicos
- Comparaci√≥n de frecuencias entre diferentes d√©cadas

### Investigaci√≥n Digital Humanities

- An√°lisis de cambios en el discurso web hist√≥rico
- Estudio de tendencias tem√°ticas en documentos archivados
- Investigaci√≥n de patrones de uso de lenguaje en la web temprana

### An√°lisis de Tendencias Tecnol√≥gicas

- Identificaci√≥n de t√©rminos emergentes en tecnolog√≠a
- An√°lisis retrospectivo de adopci√≥n de conceptos
- Estudio de evoluci√≥n del vocabulario t√©cnico

## Testing y Validaci√≥n

### Suite de Pruebas

El sistema incluye una suite completa de pruebas unitarias:

```bash
python test_historical_analyzer.py
```

#### Categor√≠as de Pruebas

- **Pruebas unitarias**: Cada componente individual
- **Pruebas de integraci√≥n**: Flujo completo del sistema
- **Pruebas de validaci√≥n**: Filtros y l√≠mites del sistema
- **Pruebas de casos l√≠mite**: Manejo de errores y situaciones extremas

### Ejecuci√≥n de Pruebas

```bash
# Ejecutar todas las pruebas
python -m unittest test_historical_analyzer.py -v

# Ejecutar pruebas espec√≠ficas
python -m unittest test_historical_analyzer.TestInternetArchiveClient -v
```

## M√©tricas de Rendimiento

### Benchmarks T√≠picos

- **B√∫squeda**: ~2-3 segundos por p√°gina de resultados
- **Descarga**: ~4-6 segundos por documento (incluyendo rate limiting)
- **Procesamiento**: ~0.1-0.5 segundos por documento
- **An√°lisis completo**: 60-90 minutos para 600 documentos

### Optimizaciones Implementadas

- B√∫squeda paginada para manejar grandes vol√∫menes
- Cache de resultados durante la sesi√≥n
- Procesamiento eficiente de texto con regex optimizadas
- Manejo inteligente de errores y reintentos

## Estructura del C√≥digo

### Archivos Principales

```
/
‚îú‚îÄ‚îÄ historical_term_analyzer.py    # Sistema principal
‚îú‚îÄ‚îÄ test_historical_analyzer.py    # Suite de pruebas
‚îú‚îÄ‚îÄ README.md                      # Esta documentaci√≥n
‚îî‚îÄ‚îÄ examples/                      # Ejemplos de uso
    ‚îú‚îÄ‚îÄ basic_analysis.py          # An√°lisis b√°sico
    ‚îú‚îÄ‚îÄ advanced_filtering.py      # Filtrado avanzado
    ‚îî‚îÄ‚îÄ batch_processing.py        # Procesamiento por lotes
```

### Clases Principales

- `HistoricalTermAnalyzer`: Orquestador principal
- `InternetArchiveClient`: Cliente API
- `TextProcessor`: Procesador NLP
- `Document`: Modelo de datos
- `SessionMemory`: Gesti√≥n de memoria
- `Exporter`: Exportaci√≥n de resultados
- `Visualizer`: Visualizaci√≥n de datos

## Licencia y Contribuciones

### Licencia

Este proyecto est√° desarrollado con fines educativos y de investigaci√≥n. Respeta las pol√≠ticas de uso de Internet Archive.

### Contribuciones

Para contribuir al proyecto:

1. Fork del repositorio
2. Crear branch para features: `git checkout -b feature/nueva-funcionalidad`
3. Commit cambios: `git commit -m 'Agregar nueva funcionalidad'`
4. Push al branch: `git push origin feature/nueva-funcionalidad`
5. Crear Pull Request

## Contacto y Soporte

### Documentaci√≥n Adicional

- [Internet Archive API Documentation](https://archive.org/developers/index-apis.html)
- [Wayback Machine API Reference](https://archive.org/help/wayback_api.php)

### Soluci√≥n de Problemas Comunes

#### Error de Rate Limiting (429)
```
Soluci√≥n: Incrementar rate_limit_delay a 5-6 segundos
analyzer = HistoricalTermAnalyzer(rate_limit_delay=6.0)
```

#### Sin resultados encontrados
```
Soluci√≥n: Ampliar rango de a√±os o reducir especificidad de filtros
```

#### Contenido no en ingl√©s
```
Soluci√≥n: El sistema filtra autom√°ticamente, pero puedes ajustar 
los umbrales en validate_english_content()
```

---

**Desarrollado para**: Investigadores socioling√º√≠sticos y acad√©micos  
**Versi√≥n**: 1.0  
**Fecha**: Septiembre 2025  
**Autor**: Sistema de IA Especializado